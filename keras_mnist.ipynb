{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version: 1.2.2\n",
      "Tensorflow Version 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "import tensorflow as tf\n",
    "print(f\"Tensorflow Version {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keras](https://keras.io/) is a high level wrapper (API) for Tensorflow and Theano which aims to make them easier to use. Tensorflow gets quite verbose and there is a lot of detail to handle, which Keras trys to abstract away to sane defaults, while allowing the option to tinker with the tensors where wanted.\n",
    "\n",
    "# the data\n",
    "\n",
    "To get a feel for Keras, I'm seeing how it goes with MNIST. \n",
    "\n",
    "Keras already has some [datasets included](https://keras.io/datasets/), so using the ever popular mnist:\n",
    "\n",
    "> ** MNIST database of handwritten digits**\n",
    "\n",
    "> Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shapes x_train: (60000, 28, 28), y_train: (60000,), x_test: (10000, 28, 28), y_test: (10000,)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Shapes x_train: {x_train.shape}, y_train: {y_train.shape}, x_test: {x_test.shape}, y_test: {y_test.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test images are `28x28` sized images, which we need to reshape into a 1d vector to make our super simple NN deal with. \n",
    "\n",
    "Now, it's a good idea to always eyeball the data, so here goes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASMAAAEsCAYAAACIdtX4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY0RELrAxIiIX2BgRkQtsjIjIhf8DYct32YjMCG8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e09c3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(3,3, figsize=(5,5))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(x_train[i])\n",
    "    ax.set_title(f\"Class {y_train[i]}\")\n",
    "    ax.set_xticks([]) , ax.set_yticks([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=uint8)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, we've seen the data, but we need to preprocess it into a neural net friendly shape. \n",
    "\n",
    "## preprocessing the data\n",
    "\n",
    "The image data is 60K `28x28` images, and the image test data is 10K `28x28` images. We want the number of images to stay the same, while the 28x28 should become 784:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000, 784), (10000, 28, 28), (10000, 784))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = x_train.reshape(-1, 28*28)\n",
    "X_test = x_test.reshape(-1, 28*28)\n",
    "x_train.shape, X_train.shape, x_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that was easy! Moving on to the image labels:\n",
    "\n",
    "the image labels are stored as a simple numpy array, with each entry telling us what number each corresponding drawing is. Since our NN will spit out a prediction of the likelyhood of what number the drawing is, our NN will work better with the y data [one hot encoded](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing image labels\n",
      "y_train: [5 0 4 1 9 2 1 3 1 4] | y_test: [7 2 1 0 4 1 4 9 5 9]\n",
      "Y_Train encoded: [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "Y_test encoded: [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Existing image labels\")\n",
    "print(f\"y_train: {y_train[:10]} | y_test: {y_test[:10]}\")\n",
    "\n",
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print(f\"Y_Train encoded: {Y_train[0]}\")\n",
    "print(f\"Y_test encoded: {Y_test[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now our data is all ready to go!\n",
    "\n",
    "# A simple neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s - loss: 6.0309 - acc: 0.6044 - val_loss: 4.3232 - val_acc: 0.7217\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s - loss: 4.0527 - acc: 0.7317 - val_loss: 2.8648 - val_acc: 0.8099\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s - loss: 3.0998 - acc: 0.7912 - val_loss: 2.8480 - val_acc: 0.8082\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s - loss: 1.8784 - acc: 0.8621 - val_loss: 1.1092 - val_acc: 0.9163\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s - loss: 1.3703 - acc: 0.8896 - val_loss: 0.9750 - val_acc: 0.9181\n",
      "Epoch 6/10\n",
      "26368/60000 [============>.................] - ETA: 2s - loss: 1.1894 - acc: 0.8938- ETA: 6s - "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# we can either use part of the training set as validation data or provide a validation set\n",
    "#model.fit(X_train, Y_train, nb_epoch=10, batch_size=64, validation_split=0.1)\n",
    "model.fit(X_train, Y_train, nb_epoch=10, batch_size=128, shuffle=True, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
