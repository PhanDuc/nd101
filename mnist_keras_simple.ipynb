{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version: 2.0.4\n",
      "Tensorflow Version 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "import tensorflow as tf\n",
    "print(f\"Tensorflow Version {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keras](https://keras.io/) is a high level wrapper (API) for Tensorflow and Theano which aims to make them easier to use. Tensorflow gets quite verbose and there is a lot of detail to handle, which Keras trys to abstract away to sane defaults, while allowing the option to tinker with the tensors where wanted.\n",
    "\n",
    "# the data\n",
    "\n",
    "To get a feel for Keras, I'm seeing how it goes with MNIST. \n",
    "\n",
    "Keras already has some [datasets included](https://keras.io/datasets/), so using the ever popular mnist:\n",
    "\n",
    "> ** MNIST database of handwritten digits**\n",
    "\n",
    "> Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shapes x_train: (60000, 28, 28), y_train: (60000,), x_test: (10000, 28, 28), y_test: (10000,)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Shapes x_train: {x_train.shape}, y_train: {y_train.shape}, x_test: {x_test.shape}, y_test: {y_test.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test images are `28x28` sized images, which we need to reshape into a 1d vector to make our super simple NN deal with. \n",
    "\n",
    "Now, it's a good idea to always eyeball the data, so here goes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min to max values in x_train\n",
    "x_train.min(), x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASMAAAEsCAYAAACIdtX4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1247b6630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(3,3, figsize=(5,5))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(x_train[i])\n",
    "    ax.set_title(f\"Class {y_train[i]}\")\n",
    "    ax.set_xticks([]) , ax.set_yticks([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, we've seen the data, but we need to preprocess it into a neural net friendly shape. \n",
    "\n",
    "## preprocessing the data\n",
    "\n",
    "The image data is 60K `28x28` images, and the image test data is 10K `28x28` images. We want the number of images to stay the same, while the 28x28 should become 784. Since the data is just numpy arrays we can use [np.reshape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000, 784), (10000, 28, 28), (10000, 784))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = x_train.reshape(-1, 28*28)\n",
    "X_test = x_test.reshape(-1, 28*28)\n",
    "x_train.shape, X_train.shape, x_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that was easy! \n",
    "\n",
    "Now, often image data is normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "X_train.min(), X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to the image labels:\n",
    "\n",
    "the image labels are stored as a simple numpy array, with each entry telling us what number each corresponding drawing is. Since our NN will spit out a prediction of the likelyhood of what number the drawing is, our NN will work better with the y data [one hot encoded](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing image labels\n",
      "y_train: [5 0 4 1 9 2 1 3 1 4] | y_test: [7 2 1 0 4 1 4 9 5 9]\n",
      "Y_Train encoded: [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "Y_test encoded: [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Existing image labels\")\n",
    "print(f\"y_train: {y_train[:10]} | y_test: {y_test[:10]}\")\n",
    "\n",
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print(f\"Y_Train encoded: {Y_train[0]}\")\n",
    "print(f\"Y_test encoded: {Y_test[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now our data is all ready to go!\n",
    "\n",
    "# A simple neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57000 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "57000/57000 [==============================] - 2s - loss: 0.5113 - acc: 0.8507 - val_loss: 0.1846 - val_acc: 0.9473\n",
      "Epoch 2/5\n",
      "57000/57000 [==============================] - 2s - loss: 0.2514 - acc: 0.9245 - val_loss: 0.1419 - val_acc: 0.9613\n",
      "Epoch 3/5\n",
      "57000/57000 [==============================] - 2s - loss: 0.2007 - acc: 0.9401 - val_loss: 0.1184 - val_acc: 0.9663\n",
      "Epoch 4/5\n",
      "57000/57000 [==============================] - 2s - loss: 0.1730 - acc: 0.9476 - val_loss: 0.1033 - val_acc: 0.9707\n",
      "Epoch 5/5\n",
      "57000/57000 [==============================] - 2s - loss: 0.1534 - acc: 0.9529 - val_loss: 0.0959 - val_acc: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12cb13fd0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# we can either use part of the training set as validation data or provide a validation set\n",
    "model.fit(X_train, Y_train, epochs=5, batch_size=128, shuffle=True, validation_split=0.05)\n",
    "\n",
    "#model.fit(X_train, Y_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9472/10000 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12318717645853758, 0.9627]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "and viola, this super simple NN gets 96% accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 27,882\n",
      "Trainable params: 27,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-76ccf9f49c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "model.history.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
