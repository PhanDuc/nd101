{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main library used by the book\n",
    "import numpy as np \n",
    "\n",
    "# cause graphs\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images-na.ssl-images-amazon.com/images/I/61gAY7APCQL._SX397_BO1,204,203,200_.jpg) \n",
    "\n",
    "This jupyter notebook contains my notes while reading [Grokking Deep Learning by Andrew Trask](https://www.manning.com/books/grokking-deep-learning). The book is sold as \"a very gentle introduction to Deep Learning\" and covers the intuition more than the theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Introducing Deep Learning\n",
    "\n",
    "Deep Learning (DL) is is an intersection of Machine Learning (ML) & Artificial Intelligence (AI). This book covers the science under the hood of the major DL frameworks so you can understand whats going on when you use popular DL frameworks like Torch, Tensorflow, Keras, etc.\n",
    "\n",
    "The book covers everything past high school maths needed to grok DL. Find a personal problem I'm interested in which to apply DL to. This couldbe anything where there is a dataset to predict another. Trask (the author) used Twiter to predict the stock market, which led him from barely knowing programming to a job at a hedge fund in 18 months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Fundamental Concepts\n",
    "\n",
    "DL uses a subset of ML methods, primarily Artificial Neural Networks. \n",
    "\n",
    "## Supervised vs Unsupervised ml\n",
    "\n",
    "Two main types of ML:\n",
    "\n",
    "- Direct imitation, or formally **supervised ml** is basically a computer looking at a dataset A which predicts B, say weather sensor data predicting probability of rain, and trying to figure out the pattern b/w an input (sensor data) and a output set (actual weather), so when given a new input set it can apply the earlier learned pattern and come up with a prediction.\n",
    "- Indirect imitation, or fomally **unsupervised ml** looks at a not previously understoond dataset A and tries to find patterns in it. For example, it sorts data into a bunch of clusters. Clustering is the essensce of unsupervised ml. The computer doesn't know what the clusters mean but thats where the human comes in.\n",
    "\n",
    "## Parametric vs Non-Parametric Learning\n",
    "\n",
    "A parametric model has a fixed number of parameters to change, while a non-parametric model has infinite parameters.\n",
    "\n",
    "Supervised parametric dl models take in input data, process them based on a fixed number of adjustable parameters and makes a prediction. The ml model learns the optimium parameters by comparing its predictions to the actual truth, then going back and tinkering with the parameters.\n",
    "\n",
    "Unsupervised parametric dl models are similar to the supervised since they also use parameters, but they cluster the data into groups and come up with as many parameters as needed.  \n",
    "\n",
    "DL algos can be either supervised or unsupervised, and either parametric or non-parametric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chp 3: Introduction to Neural Prediction\n",
    "\n",
    "When using data to predict something, u need as many datapoints as you think the neural net needs to be accurate. For example, when trying to predict if something is in an image, you probabbly need to feed the neural net the entire image.\n",
    "\n",
    "> Always present enough information to the network, where \"enough information\" is definned loosely as how much a human might need to make the same prediction.\n",
    "\n",
    "## simplest possible neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8500000000000001"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the network\n",
    "weight = 0.1\n",
    "def neural_network(input, weight):\n",
    "    prediction = input * weight\n",
    "    return prediction\n",
    "\n",
    "# using the network to predict something\n",
    "number_of_toes = [8.5, 9.5, 10, 9]\n",
    "input = number_of_toes[0]\n",
    "pred = neural_network(input,weight)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to manipulate vectors is a cornerstone technique for Deep Learning. Some functions to do vector math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def elementwise_multiplication(vec_a, vec_b):\n",
    "    return [vec_a[i] * vec_b[i] for i in range(len(vec_a))]\n",
    "\n",
    "def vector_sum(vec_a):\n",
    "    return sum(vec_a)\n",
    "\n",
    "def elementwise_addition(vec_a, vec_b):\n",
    "    return [vec_a[i] + vec_b[i] for i in range(len(vec_a))]\n",
    "    \n",
    "def vector_average(vec_a):\n",
    "    return sum(vec_a) / len(vec_a)\n",
    "\n",
    "a = [2,2,4]\n",
    "b = [3,3,9]\n",
    "\n",
    "# to get the dot product of a and b\n",
    "vector_sum(elementwise_multiplication(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the [wikipedia example of a dot product](https://en.wikipedia.org/wiki/Dot_product):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 3, -5]\n",
    "b = [4, -2, -1]\n",
    "vector_sum(elementwise_multiplication(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural net with 3 inputs and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "0.98\n",
      "1.11\n",
      "1.15\n",
      "1.08\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([0.1, 0.2, 0])\n",
    "def neural_network(input, weights):\n",
    "    pred = input.dot(weights)\n",
    "    return pred\n",
    "\n",
    "toes = np.array([8.5, 9.5, 9.9, 9.0])\n",
    "wlrec = np.array([0.65, 0.8, 0.8, 0.9])\n",
    "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
    "\n",
    "# input corresponds to every entry for the  first game of the season\n",
    "input = np.array([toes[0], wlrec[0], nfans[0]])\n",
    "print(neural_network(input, weights))\n",
    "\n",
    "# to go through all the inputs\n",
    "for input in zip(toes,wlrec,nfans):\n",
    "    print(neural_network(np.array(input), weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural net with 3 inputs and 3 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55500000000000005, 0.98000000000000009, 0.96500000000000008]\n",
      "[0.64000000000000001, 1.1100000000000001, 1.1699999999999999]\n",
      "[0.92000000000000004, 1.1500000000000001, 1.0900000000000001]\n",
      "[0.68999999999999995, 1.0800000000000001, 1.2700000000000002]\n"
     ]
    }
   ],
   "source": [
    "weights = [[0.1, 0.1, -0.3], [0.1, 0.2, 0.0], [0.0, 1.3, 0.1]]\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = vect_mat_mul(input,weights)\n",
    "    return pred\n",
    "\n",
    "def vect_mat_mul(vect,matrix):\n",
    "    out = []\n",
    "    for m in matrix:\n",
    "        out.append(np.dot(vect,m))\n",
    "    return out\n",
    "        \n",
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "# to go through all the inputs\n",
    "for input in zip(toes,wlrec,nfans):\n",
    "    print(neural_network(input, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a stacked neural network \n",
    "\n",
    "3 inputs and 3 outputs, with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a neural net with descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 70.0000007766\n",
      "weights: [ 103.47539901   43.9901596     1.4099016 ]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([0.25,1.0,0.1])\n",
    "target = 70 # my weight\n",
    "weights = np.array([1,3,1])\n",
    "learning_rate = 0.1\n",
    "\n",
    "for epoch in range(40):\n",
    "    pred = np.dot(inputs, weights)\n",
    "    error = (pred - target)**2\n",
    "    delta_error = input * (pred - target)\n",
    "    weights = weights - (delta_error * learning_rate)\n",
    "print('pred:', pred)\n",
    "print('weights:', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Learning Multiple Weights at a Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent with Multiple Inputs & Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.3549355,  1.524418 , -0.624401 ]), [0.0, 1, 0.0])"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 1: empty network\n",
    "weights = [ [0.1, 0.1, -0.3], #hurt\n",
    "           [0.1, 0.2, 0.0], #win\n",
    "           [0.0, 1.3, 0.1] ]#sad?\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = np.dot(input, weights)\n",
    "    return pred\n",
    "\n",
    "#Predict\n",
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65,0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "hurt = [0.1, 0.0, 0.0, 0.1]\n",
    "win =[1, 1, 0, 1]\n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "alpha = 0.01\n",
    "input = [toes[0],wlrec[0],nfans[0]]\n",
    "true = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "pred = neural_network(input, weights)\n",
    "\n",
    "error = [0,0,0]\n",
    "delta = [0,0,0]\n",
    "\n",
    "for i in range(len(true)):\n",
    "    error[i] = (pred[i] - true[i]) ** 2\n",
    "    delta[i] = pred[i] - true[i]\n",
    "\n",
    "def outer_prod(vec_a, vec_b):\n",
    "    out = np.zeros((len(vec_a), len(vec_b)))\n",
    "        \n",
    "    for i in range(len(vec_a)):\n",
    "        for j in range(len(vec_b)):\n",
    "            out[i][j] = vec_a[i]*vec_b[j]\n",
    "    return out\n",
    "\n",
    "#updating the weights\n",
    "weight_deltas = outer_prod(input,delta) * alpha\n",
    "weights = np.array(weights) - weight_deltas\n",
    "\n",
    "neural_network([toes[1],wlrec[1],nfans[1]], weights), [hurt[1], win[1], sad[1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the below is a shitfight\n",
    "The [digits dataset](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits) contains 1,797 8x8 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
       "       ..., \n",
       "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
       "       [  0.,   0.,  10., ...,  12.,   1.,   0.]])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "print(digits.data.shape)\n",
    "digits.data # the actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a visual representation of the image data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11277d908>"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0iI4gMJUXwgof8A4C6Y4wlBav8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112927c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(digits.images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits.target contains what each datapoint represents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(digits.target.shape)\n",
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the image above, which looks like a zero, so digits.data[0] should be equal to digits.target[0], is equal to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now to build out a nerual net to classify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = digits.data\n",
    "targets = digits.target\n",
    "#one weight per input pixel\n",
    "hidden_weights = np.random.random([64,10])\n",
    "output_weights = np.random.random(10)\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the dot product of each input vector and the weights gives us 10 outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_input = np.dot(inputs[0], hidden_weights)\n",
    "hidden_output = sigmoid(hidden_input)\n",
    "hidden_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the dot product of the hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (64,) and (10,) not aligned: 64 (dim 0) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-471-4176378f2761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (64,) and (10,) not aligned: 64 (dim 0) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.dot(a, output_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the output numbers seem pretty high, so we might want to normalize the incoming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inputs = np.random.random([len(digits.data),64]) # a blank input\n",
    "#for i, item in enumerate(digits.data):\n",
    "#    inputs[i] = ((item - digits.data.mean()) / digits.data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.8117562 , -0.8117562 ,  0.01925204, ..., -0.8117562 ,\n",
       "        -0.8117562 , -0.8117562 ],\n",
       "       [-0.8117562 , -0.8117562 , -0.8117562 , ...,  0.85026027,\n",
       "        -0.8117562 , -0.8117562 ],\n",
       "       [-0.8117562 , -0.8117562 , -0.8117562 , ...,  1.84747015,\n",
       "         0.68405863, -0.8117562 ],\n",
       "       ..., \n",
       "       [-0.8117562 , -0.8117562 , -0.64555455, ...,  0.18545368,\n",
       "        -0.8117562 , -0.8117562 ],\n",
       "       [-0.8117562 , -0.8117562 , -0.4793529 , ...,  1.18266357,\n",
       "        -0.8117562 , -0.8117562 ],\n",
       "       [-0.8117562 , -0.8117562 ,  0.85026027, ...,  1.18266357,\n",
       "        -0.64555455, -0.8117562 ]])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculating the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -3.06830336,  -4.76420192,  -4.85003619, ...,  -2.76972724,\n",
       "          2.21539197,   0.93605365],\n",
       "       [ -3.52793678,   0.08871104,  -3.77219696, ...,  -3.08459096,\n",
       "          2.10678359,   0.32016976],\n",
       "       [  1.51288988,   2.80620158,  -2.84952504, ...,  -0.77463449,\n",
       "          6.00694037,   4.89467518],\n",
       "       ..., \n",
       "       [  0.80117623,   3.1278505 ,  -1.25573866, ...,   3.34908273,\n",
       "          8.75502707,   7.78887479],\n",
       "       [ -1.41450206,   0.37686184,  -0.51405872, ...,   0.62209819,\n",
       "          6.90003339,   4.66896045],\n",
       "       [  2.31815972,   5.54513861,   1.42283582, ...,   4.83149732,\n",
       "         10.66877677,   9.76844909]])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_inputs = np.dot(inputs, hidden_weights)\n",
    "print(hidden_inputs.shape)\n",
    "hidden_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sigmoid function to calculate the output of the hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04443381,  0.00845755,  0.00776729, ...,  0.05898215,\n",
       "         0.90162322,  0.71830182],\n",
       "       [ 0.02852771,  0.52216323,  0.0224843 , ...,  0.04374736,\n",
       "         0.89156076,  0.57936562],\n",
       "       [ 0.81948909,  0.94301003,  0.05470587, ...,  0.31547743,\n",
       "         0.99754444,  0.99256929],\n",
       "       ..., \n",
       "       [ 0.69022603,  0.95802704,  0.22170833, ...,  0.96607479,\n",
       "         0.99984236,  0.99958585],\n",
       "       [ 0.19552493,  0.593116  ,  0.37424255, ...,  0.6506956 ,\n",
       "         0.99899326,  0.99070519],\n",
       "       [ 0.91036989,  0.9961088 ,  0.8057826 , ...,  0.99208852,\n",
       "         0.99997674,  0.99994277]])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_outputs = sigmoid(hidden_inputs)\n",
    "print(hidden_outputs.shape)\n",
    "hidden_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hidden layer gives 10 outputs for each of the 1797 data points.\n",
    "\n",
    "Now to predict the output neural layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3., ...,  4.,  3.,  5.])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pred = np.dot(hidden_outputs, output_weights) \n",
    "final_outputs = output_pred.round(0)\n",
    "print(final_outputs.shape)\n",
    "final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the output errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.,   1.,   1., ...,  16.,  36.,   9.])"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_errors = (final_outputs - digits.target)**2\n",
    "print(output_errors.shape)\n",
    "output_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., -3., -4., -2., -4., -6., -4., -7.])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_delta = final_outputs - digits.target\n",
    "output_delta[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how to adust the weights now that we have the output errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to multiply each of the 1797 final errors with the output weights. So we need to iterate through each of the data arrays and corresponding targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weights\n",
    "ih_weight = np.random.random([64,10])\n",
    "ho_weight = np.random.random(10)\n",
    "learning_rate = 0.01\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for input, target in zip(digits.data, digits.target):\n",
    "        hidden_layer = np.dot(input, ih_weight)\n",
    "        hidden_outputs = sigmoid(hidden_inputs)\n",
    "\n",
    "        output_pred = np.dot(hidden_outputs, ho_weight) \n",
    "        output = output_pred.round(0)\n",
    "\n",
    "        # so now we have a prediction. time to back propagate!\n",
    "\n",
    "        #starting with the output errors:\n",
    "        error = output - target\n",
    "\n",
    "        output_error = error * output * (1 - output)\n",
    "\n",
    "        output_weight_delta = np.dot(ho_weight, output_delta) * learning_rate\n",
    "\n",
    "        ho_weight -= output_weight_delta * learning_rate\n",
    "    \n",
    "def neural_net(input)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -528.315657  ,  -498.88232425,  -965.34318155, -1118.71371346,\n",
       "        -913.29027258,  -461.29240453,  -609.00620295, -1384.59160212,\n",
       "        -428.01193233,  -584.50716073])"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_weight_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17615.80505652,  16634.39963162,  32187.75948365,  37301.64425246,\n",
       "        30452.14198882,  15381.02640839,  20306.2968269 ,  46166.89932013,\n",
       "        14271.3445303 ,  19489.41709594])"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ho_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ih_weight_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
